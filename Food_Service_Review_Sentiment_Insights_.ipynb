{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FOOD SERVICE REVIEW SENTIMENT ANALYSIS\n",
        "\n",
        "### Hello! Thanks for viewing my project.\n",
        "\n",
        "#### Today we'll be working on a food service review sentiment analysis model.\n",
        "\n",
        "#### This model will help us:\n",
        "\n",
        "- Classify the reviews on an online food service app as good, bad, or neutral\n",
        "- Help identify the major weaknesses and strengths based on the customer reviews"
      ],
      "metadata": {
        "id": "FF_NcrIcAkId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Let's get started if you're ready!"
      ],
      "metadata": {
        "id": "x9Rcw1qFBgEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### For this project, I'd be using the Textblob library for the classification model.\n",
        "\n",
        "It seems like a good choice because this project is not very complex, and therefore doesn't require complex algorithms."
      ],
      "metadata": {
        "id": "MFCL3CUxBlBH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k65IZMkSAHVc",
        "outputId": "e81050b2-ece0-45c6-ded9-533f76bbb76e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n",
            "Finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Now, we'll import the reuired libraries into our code this way:\n",
        "\n",
        "> I imported the csv library because we'd be working with csv files for this project and we will require some csv functions as we go"
      ],
      "metadata": {
        "id": "M3rkOHvQCRhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from textblob import TextBlob\n",
        "from textblob.classifiers import NaiveBayesClassifier"
      ],
      "metadata": {
        "id": "KUNzqXcbCKnE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### My data wasn't perfect so I ran into some errors\n",
        "#### The code below shows how I handled the errors but still, permit me to talk about it a bit here:\n",
        "\n",
        "- So the code below normally should be as simple as  ABC. But the errors I encountered made it a bit of a hassle.\n",
        "\n",
        "- The csv file 'foodreviewtrain.csv', as the name says, contains food reviews and the tags that classify them as either good, bad, or neutral.\n",
        "\n",
        "- But some of the text contained comma and since the whole concept of CSV revolves around the use of comma to separate data. I got an error.\n",
        "\n",
        "- So to read the CSV file, I had to open the file and change all the commas to semi colon and then indicate right here in our code that the delimiter is semi colon.\n",
        "\n",
        "- Next, I appended the trainin data list with the content of the csv file using a for loop and I used a try-except block to handle any errors that may occur during the process."
      ],
      "metadata": {
        "id": "8S2RXGWVGsT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = []\n",
        "with open(\"foodreviewtrain.csv\", \"r\", encoding=\"latin-1\") as file:\n",
        "    reader = csv.reader(file, delimiter=\";\")\n",
        "    next(reader) # this line skips the header row\n",
        "    for row in reader:\n",
        "        try:\n",
        "            feedback = row[0]\n",
        "            tag = row[1]\n",
        "            train_data.append((feedback, tag))\n",
        "        except IndexError:\n",
        "            print(\"Invalid row\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7F3FYGzKCA5D",
        "outputId": "e4a661e9-b8cb-4948-de2b-b57e84c873e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Invalid row: []\n",
            "Invalid row: []\n",
            "Invalid row: []\n",
            "Invalid row: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Glee! We've been able to preprocess our data\n",
        "\n",
        "Now, we train the NaiveBayesClassifier with the preprocessed data"
      ],
      "metadata": {
        "id": "lbOkd1b-Mb4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cl = NaiveBayesClassifier(train_data)"
      ],
      "metadata": {
        "id": "bp8NsafWMYQQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cool! We've trained our classifier.\n",
        "#### Now, let's load our testing data the exact way we did for the training data (well, not entirely the same but you know, almost the same to avoid errors and headache)"
      ],
      "metadata": {
        "id": "qsUrtL02Nlsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "with open('foodreviewtest.csv', 'r', encoding='latin-1') as file:\n",
        "    read = csv.reader(file, delimiter=';') # we used read instead of reader\n",
        "    next(read)  # Just like before, this line skips the header row\n",
        "    for row in read:\n",
        "        try:\n",
        "            sentence = row[0]\n",
        "            tag = row[1]\n",
        "            test_data.append((sentence, tag))\n",
        "        except IndexError:\n",
        "            print(\"Invalid row\")"
      ],
      "metadata": {
        "id": "XmYl4gGKNU4v"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Yay! We did it!\n",
        "#### Now let's see if our model is a good one.\n",
        "\n",
        "> We'll calculate the accuracy score as done below:"
      ],
      "metadata": {
        "id": "rIgTrdsGOn4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy\n",
        "accuracy = cl.accuracy(test_data)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UNEU9ORObq3",
        "outputId": "4944caba-f8b1-4473-8aff-afb911ec91a8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our model seems like a good one! Now we're ready to experiment with real world data"
      ],
      "metadata": {
        "id": "raHem0NZO2ex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We're going to test our model with the reviews on a food service app on playstore named 'Eden'\n",
        "\n",
        "Now, I could just copy and paste a bunch of reviews from the playstore site but I decided to get my hands on beautifulsoup and requests libraries to do the job for me.\n",
        "\n",
        "> P.S. By the job, I mean web scraping!"
      ],
      "metadata": {
        "id": "w1C3gfSVO_df"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "yeeX6WXL9_un"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = \"https://play.google.com/store/apps/details?id=com.ouredenlife.app&hl=en&gl=US&pli=1\"\n",
        "\n",
        "response = requests.get(url) # This line sends a GET request to the URL\n",
        "\n",
        "# The line below creates a BeautifulSoup object to parse the HTML content\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "\n",
        "# Prior to now, I had inspected the website\n",
        "# i found that the review texts were in div tags with the class 'h3YV2d'\n",
        "# They were all identical so I used the find_all function to 'find them all'\n",
        "review_divs = soup.find_all(\"div\", class_=\"h3YV2d\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Now, with a for loop, we'll extract all the text into a an empty list I created below 'review_list'"
      ],
      "metadata": {
        "id": "H-Oq47N7QTs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review_list = []\n",
        "\n",
        "for div in review_divs:\n",
        "    review = div.get_text(strip=True)\n",
        "    review_list.append(review)\n",
        "\n",
        "review_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwwYceTkQO8l",
        "outputId": "4609cb55-1a72-454e-e2de-02e8de9977e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Clean app. I just found it. But you guys lack a lot of food menu, and your cleaning service is so expensive. Maybe in the nearest future when more things have been added I will come back. Keep me up.',\n",
              " \"The app is clean and simple to use. However, I've been getting daily notifications for meals I did not order. Sometimes I get notifications in the middle of the night when I should be sleeping. Please sort out your notification system.\",\n",
              " 'The app is perpetually problematic. It requires updates, and despite this, it is slow, erratic, and unreliable. Every month, like clockwork, it fails to deduct the monthly charges. Despite regular complaints, nothing is done.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perfectos!\n",
        "#### Now, let's see if our model can classify each of the reviews above as good, bad, or neutral effectively"
      ],
      "metadata": {
        "id": "vtwb53YcQwhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classified_reviews = []\n",
        "\n",
        "# Classify each review in the list\n",
        "for review in review_list:\n",
        "    classification = cl.classify(review)\n",
        "    classified_reviews.append((review, classification))\n",
        "\n",
        "classified_reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkay-p7mQvGo",
        "outputId": "a97e51ba-cf6f-45e5-d304-958489505d28"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Clean app. I just found it. But you guys lack a lot of food menu, and your cleaning service is so expensive. Maybe in the nearest future when more things have been added I will come back. Keep me up.',\n",
              "  'good'),\n",
              " (\"The app is clean and simple to use. However, I've been getting daily notifications for meals I did not order. Sometimes I get notifications in the middle of the night when I should be sleeping. Please sort out your notification system.\",\n",
              "  'bad'),\n",
              " ('The app is perpetually problematic. It requires updates, and despite this, it is slow, erratic, and unreliable. Every month, like clockwork, it fails to deduct the monthly charges. Despite regular complaints, nothing is done.',\n",
              "  'good')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cl.accuracy(classified_reviews)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoBRBbENRcUU",
        "outputId": "7d7f9f6c-06fe-4202-e719-15378005d506"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Major words associated with the reviews that determine if they're good, bad, or neutral"
      ],
      "metadata": {
        "id": "r0qO10zBTuO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cl.show_informative_features(40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6UfbDTER9Yt",
        "outputId": "201a9123-1a4c-4a3a-a70a-cb5b60a3c24f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "            contains(my) = True              bad : neutra =     50.4 : 1.0\n",
            "           contains(had) = True             good : neutra =     39.5 : 1.0\n",
            "  contains(expectations) = True             good : neutra =     30.7 : 1.0\n",
            "          contains(than) = True           neutra : good   =     29.9 : 1.0\n",
            "      contains(expected) = True           neutra : good   =     28.0 : 1.0\n",
            "       contains(arrived) = True              bad : neutra =     24.8 : 1.0\n",
            "           contains(and) = False          neutra : bad    =     24.5 : 1.0\n",
            "            contains(no) = True           neutra : bad    =     22.1 : 1.0\n",
            "        contains(person) = True           neutra : good   =     22.0 : 1.0\n",
            "          contains(both) = True           neutra : bad    =     21.4 : 1.0\n",
            "    contains(absolutely) = True             good : bad    =     20.3 : 1.0\n",
            "      contains(friendly) = True           neutra : good   =     19.4 : 1.0\n",
            "   contains(exceptional) = True             good : neutra =     18.0 : 1.0\n",
            "             contains(a) = True              bad : neutra =     14.8 : 1.0\n",
            "          contains(took) = True           neutra : bad    =     12.8 : 1.0\n",
            "        contains(lacked) = True           neutra : bad    =     11.9 : 1.0\n",
            "    contains(completely) = True              bad : good   =     11.6 : 1.0\n",
            "      contains(pleasant) = True           neutra : good   =     10.9 : 1.0\n",
            "            contains(to) = True              bad : neutra =      9.2 : 1.0\n",
            "        contains(polite) = True           neutra : good   =      8.0 : 1.0\n",
            "          contains(late) = True           neutra : bad    =      7.1 : 1.0\n",
            "          contains(cold) = True              bad : neutra =      6.7 : 1.0\n",
            "       contains(service) = True           neutra : bad    =      5.5 : 1.0\n",
            "   contains(undercooked) = True              bad : neutra =      5.1 : 1.0\n",
            "            contains(on) = True             good : neutra =      4.8 : 1.0\n",
            "          contains(time) = True             good : neutra =      4.7 : 1.0\n",
            "        contains(flavor) = True           neutra : bad    =      4.7 : 1.0\n",
            "       contains(average) = True           neutra : bad    =      3.7 : 1.0\n",
            "        contains(tasted) = True              bad : good   =      3.6 : 1.0\n",
            "           contains(The) = False             bad : neutra =      3.5 : 1.0\n",
            "           contains(the) = False            good : neutra =      3.3 : 1.0\n",
            "            contains(in) = True              bad : good   =      3.2 : 1.0\n",
            "       contains(delayed) = True              bad : neutra =      3.1 : 1.0\n",
            "    contains(complaints) = True             good : neutra =      3.0 : 1.0\n",
            "             contains(i) = True             good : neutra =      2.8 : 1.0\n",
            "           contains(hot) = True           neutra : good   =      2.7 : 1.0\n",
            "             contains(I) = True             good : neutra =      2.6 : 1.0\n",
            "      contains(lukewarm) = True           neutra : bad    =      2.5 : 1.0\n",
            "           contains(but) = False             bad : neutra =      2.3 : 1.0\n",
            "           contains(and) = True              bad : neutra =      2.3 : 1.0\n"
          ]
        }
      ]
    }
  ]
}